{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4601ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "from importlib import reload\n",
    "import persist_to_disk as ptd\n",
    "import os\n",
    "ptd.config.set_project_path(os.path.abspath(\"../\"))\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94917adc",
   "metadata": {},
   "source": [
    "## Read the toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './demo_data.pkl'\n",
    "if not os.path.isfile(data_path):\n",
    "    import models\n",
    "    import dataeval.load as dload\n",
    "    import _settings\n",
    "    tokenizer = models.load_tokenizer('llama-13b-hf')\n",
    "    res = dload.read_cleaned_outputs_new(_settings.GEN_PATHS['trivia']['llama-13b'])\n",
    "    idx = np.random.RandomState(42).choice(len(res), 500, replace=False)\n",
    "    demo_data = []\n",
    "    for _idx in idx:\n",
    "        curr = {_k: res[_idx][_k] for _k in ['prompt', 'id', 'question', 'answer', 'generations']}\n",
    "        curr['prompt'] = tokenizer.decode(curr['prompt'])\n",
    "        curr['generations'] = {_k: _v for _k, _v in curr['generations'].items() if _k.startswith(\"text\")}\n",
    "        demo_data.append(curr)\n",
    "    pd.to_pickle(demo_data, data_path)\n",
    "demo_data = pd.read_pickle(data_path)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72904d",
   "metadata": {},
   "source": [
    "## UQ object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6117f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline.uq_bb as uq_bb\n",
    "reload(uq_bb)\n",
    "obj = uq_bb.UQ_summ(demo_data, clean=True,\n",
    "                    #split='test', cal_size=5, seed=1,\n",
    "                   gpteval_examples = [{'question': 'In Scotland a bothy/bothie is a?',\n",
    "                      'reference': 'House','answer': 'House',\n",
    "                        },\n",
    "                      {'question': 'Where in England was Dame Judi Dench born?',\n",
    "                       'reference':  'York', 'answer': 'London'\n",
    "                        }])\n",
    "# when split is not set, uses the default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ea, _ia = obj.get_acc('generations|gpt|acc')\n",
    "print(\"Expected Accuracy (mean over all generations)\")\n",
    "_ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecacdfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Individual Accuracy\")\n",
    "_ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a956fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_u, _c = obj.get_uq('generations|eccentricity|agreement_w', temperature=3., eigv_threshold=0.9)\n",
    "print(\"Uncertainty (higher=more uncertain)\")\n",
    "_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b74eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Negative) Confidence (higher=less confident)\")\n",
    "_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16314bc",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gens = 10\n",
    "summ_kwargs = {\n",
    "    'u+ea': {'overall': True, 'use_conf': False},\n",
    "    'u+ia': {'overall': False, 'use_conf': False},\n",
    "    'c+ia': {'overall': False, 'use_conf': True},\n",
    "}['c+ia']\n",
    "\n",
    "summ_obj = obj.summ([\n",
    "        'generations|numsets', 'lexical_sim',\n",
    "    \n",
    "        'generations|spectral_eigv_clip|disagreement_w',\n",
    "        'generations|eccentricity|disagreement_w',\n",
    "        'generations|degree|disagreement_w',\n",
    "\n",
    "        'generations|spectral_eigv_clip|agreement_w',\n",
    "        'generations|eccentricity|agreement_w',\n",
    "        'generations|degree|agreement_w',\n",
    "\n",
    "\n",
    "        'generations|spectral_eigv_clip|jaccard',\n",
    "        'generations|eccentricity|jaccard',\n",
    "        'generations|degree|jaccard',\n",
    "], \n",
    "    \n",
    "    acc_name='generations|gpt|acc',\n",
    "    num_gens=num_gens, **summ_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U + EA (using uncertainty to predict expected accuarcy)\n",
    "summ_obj.summ_overall('auarc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbcf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C + IA (using confidence to predict individual accuracy)\n",
    "sum(summ_obj.summ_individual('auarc', use_conf=True)) / num_gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C + IA (using confidence to predict individual accuracy)\n",
    "sum(summ_obj.summ_individual('auroc', use_conf=True)) / num_gens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c54264",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(uq_bb)\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "def name_map(v):\n",
    "    if v == 'self_prob': return \"P(true)\"\n",
    "    v = v.replace(\"|disagreement_w\", \"|(C)\")\n",
    "    v = v.replace(\"|agreement_w\", \"|(E)\")\n",
    "    v = v.replace(\"|jaccard\", \"|(J)\")\n",
    "    v = v.replace(\"spectral_eigv_clip|\", \"EigV\")\n",
    "    v = v.replace(\"eccentricity|\", \"Ecc\")\n",
    "    v = v.replace(\"degree|\", \"Deg\")\n",
    "    return {'numsets': 'NumSet', 'semanticEntropy|unnorm': 'SE',\n",
    "            'blind': 'Basse Accuracy'}.get(v,v)\n",
    "    return v\n",
    "summ_obj.plot('roc', name_map=name_map, \n",
    "              methods=[\n",
    "                  'generations|numsets',\n",
    "                       'generations|eccentricity|agreement_w', \n",
    "                       'generations|spectral_eigv_clip|agreement_w', \n",
    "                       'generations|degree|agreement_w', \n",
    "                  'self_prob', 'semanticEntropy|unnorm'], \n",
    "              cutoff=1, iloc=1)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(uq_bb)\n",
    "plt.figure(figsize=(6,3.5))\n",
    "def name_map(v):\n",
    "    if v == 'self_prob': return \"P(true)\"\n",
    "    v = v.replace(\"|disagreement_w\", \"|(C)\")\n",
    "    v = v.replace(\"|agreement_w\", \"|(E)\")\n",
    "    v = v.replace(\"|jaccard\", \"|(J)\")\n",
    "    v = v.replace(\"spectral_eigv_clip|\", \"EigV\")\n",
    "    v = v.replace(\"eccentricity|\", \"Ecc\")\n",
    "    v = v.replace(\"degree|\", \"Deg\")\n",
    "    return {'numsets': 'NumSet', 'semanticEntropy|unnorm': 'SE', 'oracle': \"Oracle\",\n",
    "            'blind': 'Base Accuracy'}.get(v,v)\n",
    "    return v\n",
    "summ_obj.plot('arc', name_map=name_map, \n",
    "              methods=[\n",
    "                  'generations|numsets',\n",
    "                       'generations|eccentricity|agreement_w', \n",
    "                       'generations|spectral_eigv_clip|agreement_w', \n",
    "                       'generations|degree|agreement_w', \n",
    "                       'oracle', 'blind', 'self_prob', 'semanticEntropy|unnorm'], \n",
    "              cutoff=1)\n",
    "plt.xlabel(\"Rejection Rate\")\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "plt.title(\"ARC\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
